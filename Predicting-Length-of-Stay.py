# -*- coding: utf-8 -*-
"""always-have-bc-v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1APLJ1hoWBkqgmqh0eF3liIuUeHepG53x

#**Imports**
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import time
import datetime

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix

"""#**Data Imports and Preprocessing**

## Austin

### Preprocessing
"""

ai_df = pd.read_csv('./drive/Shareddrives/519/dataset/austin_in.csv')
ao_df = pd.read_csv('./drive/Shareddrives/519/dataset/austin_out.csv')

ai_df['DateTime'] = pd.to_datetime(ai_df['DateTime'])
ao_df['DateTime'] = pd.to_datetime(ao_df['DateTime'])

ai_df = ai_df.sort_values(by='DateTime')
ao_df = ao_df.sort_values(by='DateTime')

ais_df = ai_df.copy()
aos_df = ao_df.copy()

g = ais_df.groupby('Animal ID')
ais_df['Animal ID'] += g.cumcount().add(1).astype(str).radd('_').mask(g['Animal ID'].transform('count')==1,'')
g = aos_df.groupby('Animal ID')
aos_df['Animal ID'] += g.cumcount().add(1).astype(str).radd('_').mask(g['Animal ID'].transform('count')==1,'')

am_df = aos_df.merge(ais_df[['Animal ID', 'DateTime']], on='Animal ID')
am_df = am_df.rename(columns={'DateTime_x': 'DateTime_out', 'DateTime_y': 'DateTime_in'})

def to_cost(row):
  if row['Outcome Type'] == 'Adoption':
    if row['Animal Type'] == 'Cat':
      return 80 if row['Age in days'] < 2557 else 0
    elif row['Animal Type'] == 'Dog':
      if row['Age in days'] < 183:
        return 100
      elif row['Age in days'] < 2557:
        return 80
      else:
        return 0

am_df['Date of Birth'] = pd.to_datetime(am_df['Date of Birth'])
am_df['Age in days'] = (am_df['DateTime_out'] - am_df['Date of Birth']).dt.days
am_df['Cost'] = am_df.apply(to_cost, axis=1)
am_df['Days Stayed'] = (am_df['DateTime_out'] - am_df['DateTime_in']).dt.days

invalid = am_df[(am_df['Outcome Type'] == 'Adoption') & (am_df['Days Stayed'] < 0)]['Animal ID'].tolist()

for i, v in enumerate(invalid):
  if v.find('_') != -1:
    invalid[i] = invalid[i][:-2]

am_df['Outcome Type'].unique()

invalid_rows = ao_df[ao_df['Animal ID'].isin(invalid)].sort_values(by='DateTime').groupby('Animal ID').nth(0)
merged = ao_df.merge(invalid_rows, how='left', indicator=True)
merged = merged[merged['_merge'] == 'left_only']

ao_df = merged.drop(columns={'_merge'})

am_df.to_csv('austin_joined.csv')

"""### Analysis"""

au_df = pd.read_csv('./drive/Shareddrives/519/dataset/austin_joined.csv')

au_df['Intake Date'] = pd.to_datetime(au_df['Intake Date']).dt.date
au_df['Outcome Date'] = pd.to_datetime(au_df['Outcome Date']).dt.date

au_df.columns

au_df[au_df['Outcome Type'] == 'Adoption'].groupby('Outcome Subtype', dropna=False)['Animal ID'].count()

au_df.to_csv('austin_joined.csv', index=False)

au_df = au_df[au_df['Age in Days'] >= 0]

"""## Bloomington"""

bl_df = pd.read_csv('./drive/Shareddrives/519/dataset/bloomington.csv')

bl_df = bl_df[['id', 'intakedate', 'animalname', 'breedname', 'basecolour', \
               'speciesname', 'animalage', 'sexname', 'movementdate', 'movementtype']]
bl_df['id'] = bl_df['id'].apply(str)
bl_df['Outcome Subtype'] = np.nan
bl_df = bl_df.rename({'id': 'Animal ID', 'intakedate': 'Intake Date', 'animalname': 'Name', \
              'breedname': 'Breed', 'basecolour': 'Color', 'speciesname': 'Animal Type', \
              'sexname': 'Sex', 'movementdate': 'Outcome Date', \
              'movementtype': 'Outcome Type'}, axis=1)

bl_df = bl_df.drop_duplicates()
bl_df = bl_df[bl_df['Intake Date'].notnull() & bl_df['Outcome Date'].notnull()]
bl_df['Intake Date'] = pd.to_datetime(bl_df['Intake Date']).dt.date
bl_df['Outcome Date'] = pd.to_datetime(bl_df['Outcome Date']).dt.date
bl_df = bl_df.sort_values(by='Outcome Date')

def to_age_in_days(row):
  words = row['animalage'].split(' ')
  month = 0
  for i, w in enumerate(words):
    if w.startswith('y'):
      words[i] = 'y'
    if w.startswith('m'):
      month = int(words[i-1])
      words[i-1] = '0'
      words[i] = 'm'
    if w.startswith('w'):
      words[i] = 'w'
    if w.startswith('d'):
      words[i] = 'd'
  month_str = '{} d'.format(month * 30)
  try:
    age = pd.to_timedelta(' '.join(words)) + pd.to_timedelta(month_str)
  except:
    return np.nan
  
  td = row['Outcome Date'] - row['Intake Date']
  return td.days + age.days

def to_cost(row):
  if row['Outcome Type'] == 'Adoption' and row['Animal Type'] in ['Cat', 'Dog']:
      return 75 if row['Age in Days'] < 1827 else 55

def to_my(dto):
  my = dto.strftime('%b %Y')
  return my

def to_days_stayed(row):
  if row['Animal Type'] in ['Cat', 'Dog']:
    return (row['Outcome Date'] - row['Intake Date']).days

bl_df['Age in Days'] = bl_df.apply(to_age_in_days, axis=1)
bl_df['Cost'] = bl_df.apply(to_cost, axis=1)
bl_df['MonthYear'] = bl_df['Outcome Date'].apply(to_my)
bl_df['Days in Shelter'] = bl_df.loc[bl_df[bl_df['Outcome Type'] == 'Adoption'].groupby(['Animal ID']).head(1).index].apply(to_days_stayed, axis=1)

bl_df = bl_df.drop(columns={'animalage'})
bl_df = bl_df[(bl_df['Days in Shelter'] >= 0) | (bl_df['Days in Shelter'].isnull())]

pd.concat(g for _, g in bl_df[bl_df['Outcome Type'] == 'Adoption'].groupby(['Animal ID']) if len(g) > 1)

bl_df = bl_df.drop(bl_df[(bl_df['Animal Type'].isin(['Cat', 'Dog'])) & (bl_df['Days in Shelter'].isnull())].index)

bl_df = bl_df[['Animal ID', 'Name', 'Intake Date', 'Outcome Date', 'MonthYear',
       'Outcome Type', 'Outcome Subtype', 'Animal Type', 'Sex', 'Breed',
       'Color', 'Age in Days', 'Cost', 'Days in Shelter']]

bl_df.to_csv('bloomington_cleaned.csv', index=False)

"""## Sonoma"""

so_df = pd.read_csv('./drive/Shareddrives/519/dataset/sonoma.csv')

so_df = so_df[['Name', 'Type', 'Breed', 'Color', 'Sex', 'Date Of Birth',
       'Animal ID', 'Intake Date', 'Outcome Date', 'Days in Shelter',
       'Outcome Type', 'Outcome Subtype']]

so_df = so_df[so_df['Outcome Date'].notnull()]
so_df = so_df.drop_duplicates()

so_df['Type'].unique()

so_df['Intake Date'] = pd.to_datetime(so_df['Intake Date']).dt.date
so_df['Outcome Date'] = pd.to_datetime(so_df['Outcome Date']).dt.date
so_df['Date Of Birth'] = pd.to_datetime(so_df['Date Of Birth']).dt.date
so_df = so_df.sort_values(by='Outcome Date')

def to_cost(row):
  if row['Outcome Type'] == 'ADOPTION':
    if row['Type'] == 'CAT':
      if row['Age in Days'] < 123:
        return 126.20
      elif row['Age in Days'] < 2192:
        return 90.30
      else:
        return 60.58
    elif row['Type'] == 'DOG':
      if row['Age in Days'] < 123:
        return 192.03
      elif row['Age in Days'] < 2192:
        return 144.03
      else:
        return 107.45

def to_my(dto):
  my = dto.strftime('%b %Y')
  return my

so_df['Age in Days'] = (so_df['Outcome Date'] - so_df['Date Of Birth']).dt.days
so_df['Cost'] = so_df.apply(to_cost, axis=1)
so_df['MonthYear'] = so_df['Outcome Date'].apply(to_my)

so_df = so_df[(so_df['Age in Days'] > 0) | so_df['Age in Days'].isnull()]

so_df = so_df.rename({'Type': 'Animal Type'}, axis=1)

so_df = so_df[['Animal ID', 'Name', 'Intake Date', 'Outcome Date', 'MonthYear',
       'Outcome Type', 'Outcome Subtype', 'Animal Type', 'Sex', 'Breed',
       'Color', 'Age in Days', 'Cost', 'Days in Shelter']]

so_df.to_csv('sonoma_cleaned.csv', index=False)

master_df = pd.concat([au_df, bl_df, so_df])

master_df.head()

master_df.to_csv('master.csv', index=False)

"""## Master"""

master = pd.read_csv('./drive/Shareddrives/519/dataset/master.csv')

master.columns

master = master.drop(columns=['monthyear'])

master['intake_date'] = pd.to_datetime(master['intake_date'])
master['outcome_date'] = pd.to_datetime(master['outcome_date'])

master.astype(str).replace('nan',np.nan).describe()

master.animal_type.unique()

"""#**Data Cleaning and E.D.A**

### Categorical Data Analysis & Preprocessing

We will take a closer look into columns that are crucial inputs of our model training, to see if further cleaning and analysis might be needed, starting with categorical columns.
"""

# Take a copy of the dataframe first
master_cleaned_df = master

# Find out categorical columns
master_cleaned_df.select_dtypes(exclude=[np.number]).columns

master_cleaned_df['outcome_type'].unique()

"""We noticed that there are values which seems to be the same but of a slightly different name, such as `ADOPTION` and `Adoption`. Similar issue applies to other columns as well. We will make all field values lowercase to resolve this."""

string_fields = ['outcome_type', 'outcome_subtype', 'animal_type', 'breed', 'sex', 'color']
for string_field in string_fields:
  master_cleaned_df[string_field] = master_cleaned_df[string_field].str.lower()

# Validate on one of the columns
master_cleaned_df['outcome_type'].unique()

"""#### Animal Gender & Spay/Neuter Data

The gender of animal is sometimes taken into consider during adoption, and could potentially be an important features. Taking a closer look into the data in the `sex` column, we see that it contains information on both the animal's gender and whether neutered/spayed or not (**neuter indicates male and spay indicates female**). We will update the `sex` column to include only animal's gender (`male`, `female`, or null or `unknown`), and add another column for neutered/spayed information. 
"""

master_cleaned_df['sex'].unique()

# Get the percentage of each diff gender
master_cleaned_df['sex'].value_counts(normalize=True)

"""We notice that unknown only takes up 7%, we think it is reasonable to keep this feature with unknown values being NULL for model training. """

def update_sex_info(gender_str):
  if gender_str in ['spayed female', 'intact female', 'female', 'spay']:
    return 1
  elif gender_str in ['neutered male', 'intact male', 'male', 'neutered']:
    return 0
  else:
    return None

def get_spay_or_neuter_info(gender_str):
  if gender_str in ['spayed female', 'spay', 'neutered male', 'neutered']:
    return 1
  elif gender_str in ['intact male', 'intact female']:
    return 0
  else:
    return None

master_cleaned_df['if_neutered_or_spayed'] = master_cleaned_df['sex'].apply(get_spay_or_neuter_info)
master_cleaned_df['gender'] = master_cleaned_df['sex'].apply(update_sex_info)
master_cleaned_df = master_cleaned_df.drop(columns=['sex'])
print("Possible gender values are: ", master_cleaned_df['gender'].unique())
print("Neuter/Spay info: ", master_cleaned_df['if_neutered_or_spayed'].unique())

gender_neuter_analysis_df = master_cleaned_df.groupby(['gender','if_neutered_or_spayed'])['animal_id'].count().reset_index()
gender_neuter_analysis_df = gender_neuter_analysis_df.rename(columns={'animal_id' : 'count'})

g = sns.catplot(x = 'gender', y='count', 
               hue = 'if_neutered_or_spayed',data=gender_neuter_analysis_df, height=5, aspect=4, kind='bar')
g.fig.suptitle("Animal Gender and Neuter/Spay Distribution")
g.fig.show()

"""#### Animal Outcome Data"""

# outcome_type possible values
master_cleaned_df['outcome_type'].unique()

"""We will merge some of the values that indicate the same type of outcome, such as `euthanize` and `euthanasia` etc, and `escaped`, `lost`, `stolen`, `missing`, `escaped/stolen` into one value named `escaped/stolen/lost`"""

def merge_certain_outcome_type(outcome):
  if outcome == 'euthanize':
    return 'euthanasia'
  elif outcome in ['lost', 'escaped', 'missing', 'stolen', 'escaped/stolen']:
    return 'escaped/stolen/lost'
  elif outcome in ['rto-adopt', 'rtos', 'return to owner', 'reclaimed']:
    return 'return to owner'
  else:
    return outcome

master_cleaned_df['outcome_type'] = master_cleaned_df['outcome_type'].apply(merge_certain_outcome_type)
print(master_cleaned_df['outcome_type'].unique())

outcome_types_summary = master_cleaned_df['outcome_type'].value_counts(normalize=True)*100

"""Let's look into the distribution of different outcome types."""

plt.figure(figsize=(12, 8))
plt.title("Percentage of different outcome types")
g = outcome_types_summary.plot.bar(color={"DarkOrange"})
for bar in g.patches:
  g.annotate(format(bar.get_height(), '.2f'),
                   (bar.get_x() + bar.get_width() / 2,
                    bar.get_height()), ha='center', va='center',
                   size=12, xytext=(0, 8),
                   textcoords='offset points')
  # ax.annorate
plt.show()

"""As we are interested in predicting the length of stay before animal being adopted, it is reasonable to exclude most outcome types other than adoption, such as `escaped/stolen/lost`, `relocate`, `released to wild`, `transfer`, `died`, `foster` (taking animals home only temporarily), and `return to owner` (**as owner will only consider adopting their previous animal, which introduces noises to our prediction**). What about `euthanisia`? Should euthanized animal be considered as having infinitely long length of stay as they were probably suitable for adoption, or would including euthanized animals actually introducing more noise to our training? Let's take a closer look into the `outcome_subtype` field to get more information. """

euthanasia_analysis_df = master_cleaned_df[master_cleaned_df['outcome_type'].isin(['euthanasia'])]

euthanasia_analysis_df = euthanasia_analysis_df.groupby(['outcome_type','outcome_subtype'])['animal_id'].count().reset_index()
euthanasia_analysis_df = euthanasia_analysis_df.rename(columns={'animal_id' : 'count'})
euthanasia_analysis_df = euthanasia_analysis_df.sort_values('count', ascending=False).reset_index(drop=True)

sns.set(rc={'figure.figsize':(12,9)})
g = sns.catplot(x = 'outcome_type', y='count', 
               hue = 'outcome_subtype',data=euthanasia_analysis_df, height=5, aspect=4, kind='bar')
g.fig.suptitle("Euthanasia Reasons Analysis")
g.fig.show()

"""The above diagram shows that most animals being euthanized are due to real concerns such as rabis risk (the top one reason for euthanasia), suffering, aggresive, or other illness. **Including euthanized animals in our training dataset would introduce more noises, as those animals were not suitable adoption. Hence, we decide to include data for animals with `outcome_type = adoption` only.**"""

adoption_df = master_cleaned_df[master_cleaned_df['outcome_type'] == 'adoption']

"""#### Animal Type

What are the different types of animals in the shelter?
"""

animal_types_data = adoption_df['animal_type'].value_counts(normalize=True)
animal_types_data

animal_types_aggregated_data={}
animal_types_aggregated_data['All others'] = 0
threshold = 0.003
explode = [0,0,0,0,.1,.1]

for index, value in animal_types_data.iteritems():
  if value < threshold:
    animal_types_aggregated_data['All others'] += value
  else:
    animal_types_aggregated_data[index] = value

plt.figure(figsize=(7, 7))
sizes = animal_types_aggregated_data.values()
labels = animal_types_aggregated_data.keys()
patches, texts = plt.pie(sizes, startangle=0)
plt.legend(patches, labels=['%s, %1.1f%%' % (l, (float(s) / 1) * 100) for l, s in zip(labels, sizes)], loc="best")
plt.tight_layout()
plt.show()

"""We see that other animals compose a very small percentage of all shelter animals. As we are mostly interested in predicting length of stay for dogs and animals (which are the most common animal types in most shelters), **we will filter out other animal types and focus on dogs and cats only**. """

adoption_df = adoption_df[adoption_df['animal_type'].isin(['dog', 'cat'])]

"""#### Animal Color"""

def process_color_str(color_str):
  color_str = color_str.replace(' and ', '/')
  color_str = color_str.replace(', ', '/')
  color_str = color_str.replace('blk ', 'black ')
  color_str = color_str.replace('bl ', 'blue ')
  color_str = color_str.replace('brn ', 'brown ')
  color_str = color_str.replace('br ', 'brown ')
  color_str = color_str.replace('y brindle', 'yellow brindle')
  color_str = color_str.replace('slvr ', 'silver ')
  color_str = color_str.replace('siver ', 'silver ')
  color_str = color_str.replace('pt', 'point')
  color_str = color_str.replace('tricolour', 'tricolor')
  color_str = color_str.replace('chocolate', 'choc')
  color_str = color_str.replace('with', '')
  color_str = color_str.replace(' ', '/')
  color_str = color_str.replace('golden', 'gold')
  color_str = color_str.replace('gray', 'grey')
  color_str = color_str.replace('org', 'orange')
  color_str = color_str.replace('tortie', 'torti')
  color_str = color_str.replace('tricolor', '')
  color_str = color_str.replace('various', '')
  return color_str

adoption_df['color'] = adoption_df['color'].apply(process_color_str)

animal_color_data = adoption_df[['color']].value_counts(normalize=True)
animal_color_data

adoption_df['color'].unique()

dummies = adoption_df['color'].str.get_dummies('/').sum()
print(dummies.sort_values(ascending = False).tail(15))

def process_color_str_after(color_str):
  color_str = color_str.replace('pink', 'other_color')
  color_str = color_str.replace('unknown', 'other_color')
  color_str = color_str.replace('cinnamon', 'other_color')
  color_str = color_str.replace('ruddy', 'other_color')
  color_str = color_str.replace('siver', 'other_color')
  color_str = color_str.replace('agouti', 'other_color')
  return color_str


adoption_df['color'] = adoption_df['color'].apply(process_color_str_after)

dummies = adoption_df['color'].str.get_dummies('/').sum()
print(dummies.sort_values(ascending = False).tail(15))

adoption_df = pd.concat([adoption_df, adoption_df['color'].str.get_dummies(sep='/')], axis=1)

"""#### Breed Data """

adoption_df = adoption_df[(adoption_df['breed'].notnull()) & (~adoption_df['breed'].isin(['unknown', 'mix']))]

"""##### Cat"""

cat_df = adoption_df[(adoption_df['animal_type'] == 'cat') & (adoption_df['breed'].notnull()) & (adoption_df['breed'] != 'unknown')]

sorted(cat_df['breed'].unique())

import re
cat_df['breed'] = cat_df['breed'].apply(lambda x: re.sub(r' sh$', ' shorthair', x.replace(' mix', '').replace('/mix', '')
  .replace('/unknown', '').replace('sh/', 'shorthair/').replace('dsh', 'domestic shorthair')
  .replace('domestic short hair', 'domestic shorthair').replace('dlh', 'domestic long hair')
  .replace('domestic lh', 'domestic long hair').replace('domestic longhair', 'domestic long hair')
  .replace('dmh', 'domestic medium hair').replace('domestic mh', 'domestic medium hair'))
  .replace('curl shorthair', 'curl').replace('munchkin longhair', 'munchkin')
  .replace('munchkin shorthair', 'munchkin').replace('pixie-bob', 'pixiebob')
  .replace('pixiebob shorthair', 'pixiebob'))
cat_df['breed'] = cat_df['breed'].replace({'angora': 'turkish angora'})

sorted(cat_df['breed'].unique())

cc = cat_df['breed'].str.get_dummies('/').sum().reset_index(name='sum').sort_values(by='sum', ascending=False)

other_cb = cc.tail(8)['index'].tolist()

def merge_other_cb(x):
  strlist = []
  for s in x.split('/'):
    if s in other_cb:
      s = 'other cat breed'
    strlist.append(s)
  x = '/'.join(strlist)
  return x

cat_df['breed'] = cat_df['breed'].apply(merge_other_cb)

cat_df['breed'].str.get_dummies('/').columns

"""##### Dog"""

dog_df = adoption_df[(adoption_df['animal_type'] == 'dog')
  & (adoption_df['breed'].notnull()) & (~adoption_df['breed'].isin(['unknown', 'mix']))]

dog_df[dog_df['breed'].str.contains('mix')]['breed'].value_counts()

import re
def clean_dog_breed(x):
  x = (x.replace(' mix', '').replace('/mix', '').replace('/unknown', '')
  .replace('x/', '').replace(' dog', '').replace('black/tan', 'black and tan')
  .replace('alask ', 'alaskan ').replace('am pit bull ter', 'american pit bull terrier')
  .replace('amer ', 'american ').replace('anatol ', 'anatolian ')
  .replace('aust ', 'australian ').replace('belg ', 'belgian ')
  .replace(' x', '').replace('bruss ', 'brussels ')
  .replace('chesa bay ', 'chesapeake bay ').replace('eng ', 'english ')
  .replace('terr ', 'terrier ').replace('germ ', 'german ')
  .replace('ital ', 'italian ').replace('min ', 'miniature ')
  .replace('russ ter', 'russell terrier').replace('pitbull', 'pit bull')
  .replace('rhod ', 'rhodesian ').replace('scot ', 'scottish ')
  .replace('shetld ', 'shetland ').replace('wheaton ', 'wheaten ')
  .replace('st bernard ', 'st. bernard ').replace(' miniature', ' '))

  bl = ['poodle', 'chihuahua', 'collie', 'dachshund', 'fox terrier', 'schnauzer',
        'st. bernard', 'labrador retriever', 'corgi']
  bd = {'black and tan hound': 'black and tan coonhound',
        'bluetick hound': 'bluetick coonhound',
        'cavalier spaniel': 'cavalier king charles spaniel',
        'cane corso mastiff': 'cane corso',
        'catahoula': 'catahoula leopard',
        'flat coat retriever': 'flat-coated retriever',
        'jack': 'jack russell terrier',
        'patterdale terrier (fell terrier)': 'patterdale terrier',
        'saint bernard': 'st. bernard',
        'shetland sheepdog sheltie': 'shetland sheepdog',
        'staffordshire': 'staffordshire bull terrier',
        'west highland': 'west highland white terrier',
        'west highland white terrier westie': 'west highland white terrier',
        'yorkshire terrier yorkie': 'yorkshire terrier'
        }
  strlist = []
  for s in x.split('/'):
    s = re.sub(r' mix$', ' ', s)
    s = re.sub(r' ter$', ' terrier', s)
    s = re.sub(r' terr$', ' terrier', s)
    s = re.sub(r' span$', ' spaniel', s)
    s = re.sub(r' retr$', ' retriever', s)
    s = re.sub(r' pinsch$', ' pinscher', s)
    s = re.sub(r' point$', ' pointer', s)
    s = re.sub(r' heel$', ' heeler', s)
    s = re.sub(r' shep$', ' shepherd', s)
    s = re.sub(r' staff$', ' staffordshire terrier', s)
    s = re.sub(r'$miniature ', '', s)
    
    for b in bl:
      if b in s:
        s = b
    if 'german' in s and 'pointer' in s:
      s = 'german pointer'
    if s == 'shep':
      s = 'shepherd'
    if s in ['belgian malinois', 'belgian sheepdog', 'belgian shepherd malinois']:
      s = 'belgian shepherd'
    if s in ['shar pei', 'shar-pei']:
      s = 'chinese sharpei'
    if s in bd.keys():
      s = bd[s]
    if ',' in s:
      s = s[:s.find(',')]
    if 'mix' in s:
      s = s[s.find('/'):]
    strlist.append(s.strip())
  x = '/'.join(strlist)
  return x

dog_df['breed'] = dog_df['breed'].apply(clean_dog_breed)

dog_df['breed'].str.get_dummies('/').columns

bc = dog_df['breed'].str.get_dummies('/').sum().reset_index(name='sum').sort_values(by='sum', ascending = False)

other_db = bc.tail(160)['index'].tolist()

def merge_other_db(x):
  strlist = []
  for s in x.split('/'):
    if s in other_db:
      s = 'other dog breed'
    strlist.append(s)
  x = '/'.join(strlist)
  return x

dog_df['breed'] = dog_df['breed'].apply(merge_other_db)

bc.head(20)

bc.tail(160)['sum'].sum()

fig = plt.figure(figsize=(20, 6))
y = []
for i in range(len(bc)):
  y.append(bc.tail(i)['sum'].sum())
x = range(len(bc))
plt.plot(x, y)
plt.gca()

"""##### Concat Cat and Dog"""

adoption_df = adoption_df[(adoption_df['breed'].notnull()) & (~adoption_df['breed'].isin(['unknown', 'mix']))]

import re
adoption_df.loc[adoption_df['animal_type'] == 'cat', 'breed'] = \
  adoption_df[adoption_df['animal_type'] == 'cat']['breed'].apply(lambda x: re.sub(r' sh$', ' shorthair', x.replace(' mix', '').replace('/mix', '')
  .replace('/unknown', '').replace('sh/', 'shorthair/').replace('dsh', 'domestic shorthair')
  .replace('domestic short hair', 'domestic shorthair').replace('dlh', 'domestic long hair')
  .replace('domestic lh', 'domestic long hair').replace('domestic longhair', 'domestic long hair')
  .replace('dmh', 'domestic medium hair').replace('domestic mh', 'domestic medium hair'))
  .replace('curl shorthair', 'curl').replace('munchkin longhair', 'munchkin')
  .replace('munchkin shorthair', 'munchkin').replace('pixie-bob', 'pixiebob')
  .replace('pixiebob shorthair', 'pixiebob'))

adoption_df.loc[adoption_df['animal_type'] == 'cat', 'breed'] = \
  adoption_df[adoption_df['animal_type'] == 'cat']['breed'].replace({'angora': 'turkish angora'})
adoption_df.loc[adoption_df['animal_type'] == 'cat', 'breed'] = \
  adoption_df[adoption_df['animal_type'] == 'cat']['breed'].apply(merge_other_cb)

adoption_df.loc[adoption_df['animal_type'] == 'dog', 'breed'] = \
  adoption_df[adoption_df['animal_type'] == 'dog']['breed'].apply(clean_dog_breed)
adoption_df.loc[adoption_df['animal_type'] == 'dog', 'breed'] = \
  adoption_df[adoption_df['animal_type'] == 'dog']['breed'].apply(merge_other_db)

adoption_df['breed'].unique()

adoption_df = pd.concat([adoption_df, adoption_df['breed'].str.get_dummies(sep='/')], axis=1)

"""### Numerical Data Analysis & Preprocessing"""

print(adoption_df.columns)

# Find out numerical columns
numeric_columns = adoption_df.select_dtypes(include=[np.number]).columns
numeric_columns

"""The `dats_in_shelter` fields calculated the `intake_date` and `outcome_date`. Let's validate the results."""

# Validate the calculated days in shelter
def validate_days(df):
  df['validate_days'] = df['outcome_date'] - df['intake_date']
  df['validate_days'] = df['validate_days'].apply(lambda x : x / datetime.timedelta(days=1))
  print(df[df['validate_days'] != df['days_in_shelter']])


validate_days(adoption_df)

"""We notice that there are some entries with `days_in_shelter` being null. This because when processing one of our dataset (Bloomington) data, we notice that there might be multiple outcome_date associate with one intake_date for the same entry (with the same animal ID), which should be considered as invalid data. After discussion, we have decided to keep the first recorded entry of ourcome date and ignore the rest when calculating `days_in_shelter`, which will remain those entries having a NULL `days_in_shelter`  value. As they are invalid entries, we should remove them."""

adoption_df = adoption_df[adoption_df['days_in_shelter'].isnull() == False]

# Validate days in shelter again, and drop the added `validate_days` column
validate_days(adoption_df)
adoption_df = adoption_df.drop(columns=["validate_days"])

"""Let's also visualize the number of adoptions over time (monthly data)."""

fig = plt.figure(figsize=(20, 6))
monthyear = adoption_df.groupby(by=[adoption_df.outcome_date.dt.year, adoption_df.outcome_date.dt.month])['animal_id'].count().iloc[1:-1]
ax = monthyear.plot()
ax.set_xticks(range(len(monthyear))[0::3]);
ax.set_xticklabels(["%s-%02d" % item for item in monthyear.index.tolist()[0::3]], rotation=45)
ax.set_xlabel('Adoption Date')
ax.set_ylabel('Adoption Count')
ax.set_title('Adoption Count Over Time (Monthly)')

"""### Process NULL values
We have done some filtering of our data, and let's take a look at NULL and zero values.
"""

# Check percentage of null values of selected features
def NullPercentage(df):
  print(df.apply(lambda col : col.isnull().sum()/len(col)))

NullPercentage(adoption_df)

"""We see there are a few fields with more than 10% of values being null, among which the `outcome_subtype` field has a large amount of values being NULL. **This is somewhat expected, as the `adoption_df` only contains animals that ended up being adopted, and `outcome_subtype` usually records some additional information for outcomes if needed.** Regardless, let's take a closer look into this field."""

adoption_df['outcome_subtype'].value_counts(normalize=True)

"""Noticed that `foaster` takes up >60% of `outcome_subtype`. This provides an important information, as fostered animals are **temporarily adopted** by people and will be **returned to the shelter later**. We need to filter out these entries. Other `outcome_subtype` seems to mostly record where and how animals are being adopted, and we can drop this field after filtering."""

adoption_df = adoption_df[adoption_df['outcome_subtype'] != 'foster']
adoption_df = adoption_df.drop(columns=['outcome_subtype'])

adoption_df = adoption_df[adoption_df['age_in_days'].notnull()]

"""Check the NULL percentage again after filtering. """

NullPercentage(adoption_df)

"""After filtering out fostered animals, we see there most of the entries are not NULL except for neuter/spay information, and name. Although `name` is less important for our model training, animal's neuter/spay information could potentially affect people's adoption choices. However, this information along with animal gender can be hard to keep track sometimes by the shelters, and will need to be properly addressed during feature engineering.

The final size of our dataframe is:
"""

adoption_df.shape

adoption_df.to_csv('adoption.csv', index=False)

"""### Correlation Analysis (postpone after encoding)"""

# Initialize correlation matrix
corr_matrix = adoption_df.corr()

"""Plot the correlation heatmap. -1 correlation represents the darkest red color, 0 is totally white, and +1 correlation is the blue color"""

plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, cmap='RdBu', annot=True, norm=plt.Normalize(-1.0, 1.0))

"""#**Feature Engineering**

####One-hot encode
"""

adoption_df.columns

"""We can drop columns that are not being used (for instance `animal_id`, `name`, `intake_date` and `outcome_date` which are already used for calculating the label) or have single values (`outcome_type`)"""

adoption_df = pd.get_dummies(adoption_df, columns=['animal_type', 'gender', 'if_neutered_or_spayed'])

adoption_training_df = adoption_df.drop(columns=['animal_id', 'name', 'intake_date', 'outcome_date', 'outcome_type', 'breed', 'color'])

adoption_training_df.shape

"""####Analysis and helper functions

Take a look at the days in shelter and cost distribution
"""

adoption_training_df['cost'].describe()

cost_hist = adoption_training_df['cost'].hist(bins=200, range=[0, 200])

print(adoption_training_df['age_in_days'].describe())
age_hist = adoption_training_df['age_in_days'].hist(bins=200, range=[0, 3000])

adoption_training_df['days_in_shelter'].describe()

hist = adoption_training_df['days_in_shelter'].hist(bins=200, range=[0, 150])

percentile = np.arange(1, 21, 1)

percentile = percentile* 0.05

adoption_training_df['days_in_shelter'].describe(percentiles=percentile)

def map_days_to_period(days):
  if days >= 0 and days < 5:
    return "short[0, 5)"
  elif days >= 5 and days < 11:
    return "med[5, 11)"
  elif days >= 11 and days < 30:
    return "long[11, 30)"
  else:
    return "very long(30+)"

adoption_training_df.skew().sort_values(ascending=False)

labels = ["short[0, 5)", "med[5, 11)", "long[11, 30)", "very long(30+)"]

"""####Helper Function for Obtaining Dataset"""

dog_only_cols = ['apricot',
 'liver',
 'merle',
 'sable',
 'alaskan husky',
 'american bulldog',
 'american pit bull terrier',
 'american staffordshire terrier',
 'anatolian shepherd',
 'australian cattle',
 'australian kelpie',
 'australian shepherd',
 'basset hound',
 'beagle',
 'belgian shepherd',
 'black and tan coonhound',
 'black mouth cur',
 'blue lacy',
 'border terrier',
 'boxer',
 'bully breed',
 'cairn terrier',
 'catahoula leopard',
 'chihuahua',
 'chinese sharpei',
 'chow chow',
 'collie',
 'corgi',
 'dachshund',
 'doberman pinscher',
 'fox terrier',
 'german shepherd',
 'golden retriever',
 'great dane',
 'great pyrenees',
 'hound',
 'husky',
 'jack russell terrier',
 'labrador retriever',
 'maltese',
 'mastiff',
 'miniature pinscher',
 'other dog breed',
 'parson russell terrier',
 'pit bull',
 'plott hound',
 'pointer',
 'pomeranian',
 'poodle',
 'pug',
 'queensland heeler',
 'rat terrier',
 'rottweiler',
 'schnauzer',
 'shepherd',
 'shih tzu',
 'siberian husky',
 'staffordshire bull terrier',
 'yorkshire terrier',
 'animal_type_dog',
 'animal_type_cat']

cat_only_cols = ['dilute',
 'flame',
 'lynx',
 'seal',
 'tabbico',
 'tabby',
 'torbie',
 'torti',
 'tortoiseshell',
 'abyssinian',
 'american curl',
 'american shorthair',
 'balinese',
 'bengal',
 'bombay',
 'british shorthair',
 'burmese',
 'calico',
 'cymric',
 'devon rex',
 'domestic long hair',
 'domestic medium hair',
 'domestic shorthair',
 'egyptian mau',
 'exotic shorthair',
 'extra-toes cat (hemingway polydactyl)',
 'himalayan',
 'japanese bobtail',
 'javanese',
 'maine coon',
 'manx',
 'munchkin',
 'norwegian forest cat',
 'oriental shorthair',
 'other cat breed',
 'persian',
 'pixiebob',
 'ragdoll',
 'russian blue',
 'scottish fold',
 'siamese',
 'snowshoe',
 'tonkinese',
 'turkish angora',
 'turkish van',
 'animal_type_cat',
 'animal_type_dog']

def GetDataSet(data, has_all, dog_only, cat_only, categorical, cate_func):
  if dog_only:
    ret = data[data['animal_type_dog'] == 1].copy()
    ret = ret.drop(columns=cat_only_cols)
  elif cat_only:
    ret = data[data['animal_type_cat'] == 1].copy()
    ret = ret.drop(columns=dog_only_cols)
  elif has_all:
    ret = data.copy()
  
  if categorical:
    ret['days_in_shelter'] = ret['days_in_shelter'].apply(cate_func)
  
  return ret

def log_transform(data):
  return np.log(data + 1)

# example 
# dogs_df = GetDataSet(data=adoption_training_df, has_all=False, dog_only=True, cat_only=False, categorical=True, cate_func=map_days_to_period_less)

# adoption_training_leveled_df = adoption_training_df.copy()
# adoption_training_leveled_df['days_in_shelter'] = adoption_training_leveled_df['days_in_shelter'].apply(map_days_to_period_less)
# adoption_dog_leveled_df = adoption_dog_df.copy()
# adoption_dog_leveled_df['days_in_shelter'] = adoption_dog_leveled_df['days_in_shelter'].apply(map_days_to_period_less)
# adoption_cat_leveled_df = adoption_cat_df.copy()
# adoption_cat_leveled_df['days_in_shelter'] = adoption_cat_leveled_df['days_in_shelter'].apply(map_days_to_period_less)

"""#**Model Training**

### Model Implementation

#### Logistic Regression
"""

def LogisticRegressionRunner(x_train, y_train, x_test, y_test, max_iter=3000):
  clf = LogisticRegression(random_state=0, max_iter=max_iter).fit(x_train, y_train)
  y_pred = clf.predict(x_test)
  print('LogisticRegression train accuracy score is: %.4f' %clf.score(x_train, y_train))
  print('LogisticRegression cross validation score is: %.4f' % cross_val_score(clf, x_train, y_train, cv=5).mean())
  print('LogisticRegression test accuracy score is: %.4f' %clf.score(x_test, y_test))

  # Print report from Confusion Matrix
  cm = confusion_matrix(y_test, y_pred, labels=labels)
  ax= plt.subplot()
  sns.heatmap(cm, annot=True, cmap=sns.diverging_palette(200, 20, as_cmap=True), fmt='d')
  ax.set_xlabel('Predicted')
  ax.set_ylabel('Ground Truth')
  ax.xaxis.set_ticklabels(labels)
  ax.yaxis.set_ticklabels(labels)
  print('LogisticRegression classification report:\n', classification_report(y_test,y_pred))
  return clf, y_pred

"""#### Random Forest Classification


"""

def RandomForestClassifierRunner(x_train, y_train, x_test, y_test, max_depth=18): 
  clf = RandomForestClassifier(max_depth=max_depth, random_state=0, min_samples_split=2)
  clf.fit(x_train, y_train)
  y_pred = clf.predict(x_test)
  print('RandomForestClassifier train accuracy score is: %.4f' %clf.score(x_train, y_train))
  print('RandomForestClassifier cross validation score is: %.4f' % cross_val_score(clf, x_train, y_train, cv=5).mean())
  print('RandomForestClassifier accuracy score is: %.4f' %clf.score(x_test, y_test))

  # Confusion Matrix and F1 scores
  cm = confusion_matrix(y_test, y_pred, labels=labels)
  ax= plt.subplot()
  sns.heatmap(cm, annot=True, cmap=sns.diverging_palette(200, 20, as_cmap=True), fmt='d')
  ax.set_xlabel('Predicted')
  ax.set_ylabel('Ground Truth')
  ax.xaxis.set_ticklabels(labels)
  ax.yaxis.set_ticklabels(labels)
  print('RandomForestClassifier classification report:\n', classification_report(y_test,y_pred))
  return clf, y_pred

"""####XGBClassifier"""

from xgboost import XGBClassifier

def XGBClassifierRunner(x_train, y_train, x_test, y_test, objective='multi:softmax', num_class=4, max_depth=8):
  xgb = XGBClassifier(objective=objective, num_class=num_class, max_depth=max_depth)
  xgb.fit(x_train, y_train)
  y_pred = xgb.predict(x_test)
  print('XGBClassifier train accuracy score is: %.4f' %xgb.score(x_train, y_train))
  print('XGBClassifier cross validation score is: %.4f' % cross_val_score(xgb, x_train, y_train, cv=5).mean())
  print('XGBClassifier accuracy score is: %.4f' %xgb.score(x_test, y_test))

  # Confusion Matrix and F1 scores
  cm = confusion_matrix(y_test, y_pred, labels=labels)
  ax= plt.subplot()
  sns.heatmap(cm, annot=True, cmap=sns.diverging_palette(200, 20, as_cmap=True), fmt='d')
  ax.set_xlabel('Predicted')
  ax.set_ylabel('Ground Truth')
  ax.xaxis.set_ticklabels(labels)
  ax.yaxis.set_ticklabels(labels)
  print('XGBClassifier classification report:\n', classification_report(y_test,y_pred))
  return xgb, y_pred

"""####MLP Classifier"""

from sklearn.neural_network import MLPClassifier

def MLPClassifierRunner(x_train, y_train, x_test, y_test, hidden_layer_sizes=(64, 32), max_iter=5000): 
  clf = MLPClassifier(solver='lbfgs', alpha=1e-5, batch_size=128, hidden_layer_sizes=hidden_layer_sizes, early_stopping=True)
  clf.fit(x_train, y_train)
  y_pred = clf.predict(x_test)
  print('MLPClassifier accuracy score is: %.4f' %clf.score(x_test, y_test))

  # Confusion Matrix and F1 scores
  cm = confusion_matrix(y_test, y_pred, labels=labels)
  ax= plt.subplot()
  sns.heatmap(cm, annot=True, cmap=sns.diverging_palette(200, 20, as_cmap=True), fmt='d')
  ax.set_xlabel('Predicted')
  ax.set_ylabel('Ground Truth')
  ax.xaxis.set_ticklabels(labels)
  ax.yaxis.set_ticklabels(labels)
  print('MLPClassifier classification report:\n', classification_report(y_test,y_pred))
  return clf, y_pred

"""####KNN Classifier"""

from sklearn.neighbors import KNeighborsClassifier

def KnnClassifierRunner(x_train, y_train, x_test, y_test, n_neighbors=500): 
  clf = KNeighborsClassifier(n_neighbors=n_neighbors)
  clf.fit(x_train, y_train)
  y_pred = clf.predict(x_test)
  print('KnnClassifier accuracy score is: %.4f' %clf.score(x_test, y_test))

  # Confusion Matrix and F1 scores
  cm = confusion_matrix(y_test, y_pred, labels=labels)
  ax= plt.subplot()
  sns.heatmap(cm, annot=True, cmap=sns.diverging_palette(200, 20, as_cmap=True), fmt='d')
  ax.set_xlabel('Predicted')
  ax.set_ylabel('Ground Truth')
  ax.xaxis.set_ticklabels(labels)
  ax.yaxis.set_ticklabels(labels)
  print('KnnClassifier classification report:\n', classification_report(y_test,y_pred))
  return clf, y_pred

"""#### Ridge (L2 Linear) Regression"""

def RidgeRunner(x_train, y_train, x_test, y_test, alpha=0.5):
  ridge_reg = Ridge(alpha = alpha)
  ridge_reg = ridge_reg.fit(x_train, y_train) 
  y_pred = ridge_reg.predict(x_test)
  print('L2 LinearRegression score is: %.3f' %ridge_reg.score(x_test, y_test))
  mse = mean_squared_error(y_test, y_pred)
  print('L2 LinearRegression MSE: %.3f' %mse)
  mae = mean_absolute_error(y_test, y_pred)
  print('L2 LinearRegression MAE: %.3f' %mae)

  plt.figure(figsize=(16, 10))
  plt.title("L2 LinearRegression Predictions vs Ground Truth")
  plt.scatter(range(0, len(y_test)), y_test, marker='.', label='Ground Truth')
  plt.scatter(range(0, len(y_pred)), pd.Series(y_pred), marker='+', label='Predictions')
  plt.legend()
  plt.show()

  y_train_pred = ridge_reg.predict(x_train)
  plt.figure(figsize=(16, 10))
  plt.title("LinearRegression Training Prediction vs Ground Truth")
  plt.scatter(range(0, len(y_train)), y_train, marker='+', label='Ground Truth')
  plt.scatter(range(0, len(y_train_pred)), pd.Series(y_train_pred), marker='.', label='Prediction')
  plt.legend()
  plt.show()

  prediction_and_truth_diff = y_test.subtract(pd.Series(y_pred))
  print("L2 LinearRegression prediction vs truth difference:\n", prediction_and_truth_diff.describe())

  plt.figure(figsize=(16, 10))
  plt.title("L2 LinearRegression Prediction vs Ground Truth Difference Plot")
  plt.plot(prediction_and_truth_diff, marker='.')
  plt.show()


  return ridge_reg, y_pred

"""#### RandomForestRegressor"""

def RandomForestRegressorRunner(x_train, y_train, x_test, y_test, max_depth=18, n_estimatiors=5000, criterion='squared_error'):
  rf_reg = RandomForestRegressor(n_estimators=n_estimatiors, bootstrap=True, max_features = 'sqrt', max_depth=max_depth, random_state=0, criterion=criterion)
  rf_reg.fit(x_train, y_train)
  y_pred = rf_reg.predict(x_test)
  print('RandomForestRegressor score is: %.4f' %rf_reg.score(x_test, y_test))
  mse = mean_squared_error(y_test, y_pred)
  print('RandomForestRegressor MSE: %.4f' %mse)
  mae = mean_absolute_error(y_test, y_pred)
  print('RandomForestRegressor MAE: %.4f' %mae)

  plt.figure(figsize=(16, 10))
  plt.title("RandomForestRegressor Predictions vs Ground Truth")
  plt.scatter(range(0, len(y_test)), y_test, marker='.', label='Ground Truth')
  plt.scatter(range(0, len(y_pred)), pd.Series(y_pred), marker='+', label='Prediction')
  plt.legend()
  plt.show()

  y_train_pred = rf_reg.predict(x_train)
  plt.figure(figsize=(16, 10))
  plt.title("RandomForestRegressor Training Prediction vs Ground Truth")
  plt.scatter(range(0, len(y_train)), y_train, marker='+', label='Ground Truth')
  plt.scatter(range(0, len(y_train_pred)), pd.Series(y_train_pred), marker='.', label='Prediction')
  plt.legend()
  plt.show()

  prediction_and_truth_diff = y_test.subtract(pd.Series(y_pred))
  print("RandomForestRegressor prediction vs truth difference:\n", prediction_and_truth_diff.describe())

  plt.figure(figsize=(16, 10))
  plt.title("RandomForestRegressor Prediction vs Ground Truth Difference Plot")
  plt.plot(prediction_and_truth_diff, marker='.')
  plt.show()

  return rf_reg, y_pred

"""### Train Test Split"""

def standard_scale_data(x_train, x_test):
  scaler = StandardScaler()
  scaler.fit(x_train)
  x_train = scaler.transform(x_train)
  x_test = scaler.transform(x_test)
  return x_train, x_test

def train_test_split_helper(data, label_col, test_size = 0.2):
  y = data[label_col]
  X = data.copy()
  X = X.drop(columns=[label_col])

  return train_test_split(X, y, test_size = test_size, random_state=42)

"""###Model Training, Prediction, and Analysis

####Both Dogs and Cats

#####**Regression without log transform**
"""

all_reg_df = GetDataSet(data=adoption_training_df, has_all=True, dog_only=False, cat_only=False, categorical=False, cate_func=map_days_to_period)

ar_x_train, ar_x_test, ar_y_train, ar_y_test = train_test_split_helper(all_reg_df, label_col='days_in_shelter')

ar_x_train, ar_x_test = standard_scale_data(ar_x_train, ar_x_test)

"""######**Ridge**"""

ridge, ridge_y_pred = RidgeRunner(ar_x_train, ar_y_train, ar_x_test, ar_y_test)

"""######**RandomForestRegressor**"""

rf_reg, rf_reg__y_pred = RandomForestRegressorRunner(ar_x_train, ar_y_train, ar_x_test, ar_y_test)

"""#####**Regression with log transform**"""

all_reg_df = GetDataSet(data=adoption_training_df, has_all=True, dog_only=False, cat_only=False, categorical=False, cate_func=map_days_to_period)

ar_x_train, ar_x_test, ar_y_train, ar_y_test = train_test_split_helper(all_reg_df, label_col='days_in_shelter')

ar_x_train, ar_x_test = standard_scale_data(ar_x_train, ar_x_test)

ar_y_train = log_transform(ar_y_train)
ar_y_test = log_transform(ar_y_test)

"""######**Ridge**"""

ridge, ridge_y_pred = RidgeRunner(ar_x_train, ar_y_train, ar_x_test, ar_y_test)

"""######**RandomForestRegressor**"""

rf_reg, rf_reg__y_pred = RandomForestRegressorRunner(ar_x_train, ar_y_train, ar_x_test, ar_y_test)

"""#####**Classification**"""

all_clf_df = GetDataSet(data=adoption_training_df, has_all=True, dog_only=False, cat_only=False, categorical=True, cate_func=map_days_to_period)

al_x_train, al_x_test, al_y_train, al_y_test = train_test_split_helper(all_clf_df, label_col='days_in_shelter')

al_x_train, al_x_test = standard_scale_data(al_x_train, al_x_test)

"""######**LogisticRegression**


"""

log_reg, log_y_pred = LogisticRegressionRunner(al_x_train, al_y_train, al_x_test, al_y_test)

"""######**RandomForestClassifier**"""

rf_clf, rf_clf_y_pred = RandomForestClassifierRunner(al_x_train, al_y_train, al_x_test, al_y_test)

"""######**XGBClassifier**"""

xgb, xgb_y_pred = XGBClassifierRunner(al_x_train, al_y_train, al_x_test, al_y_test)

"""######**KNN**"""

knn, knn_y_pred = KnnClassifierRunner(al_x_train, al_y_train, al_x_test, al_y_test, n_neighbors=200)

"""######**Multiclass-NeuralNet**"""

nn, nn_y_pred = MLPClassifierRunner(al_x_train, al_y_train, al_x_test, al_y_test)

"""####Dog Data Only"""

dog_df = GetDataSet(data=adoption_training_df, has_all=False, dog_only=True, cat_only=False, categorical=True, cate_func=map_days_to_period)

dog_x_train, dog_x_test, dog_y_train, dog_y_test = train_test_split_helper(dog_df, label_col='days_in_shelter')

dog_x_train, dog_x_test = standard_scale_data(dog_x_train, dog_x_test,)

"""######**LogisticRegression**


"""

dog_log, dog_log_y_pred = LogisticRegressionRunner(dog_x_train, dog_y_train, dog_x_test, dog_y_test)

"""######**RandomForestClassifier**"""

dog_rfc, dog_rfc_y_pred = RandomForestClassifierRunner(dog_x_train, dog_y_train, dog_x_test, dog_y_test)

"""######**XGBClassifier**"""

scores = cross_val_score(clf, X, y, cv=5)

dog_xgb, dog_xgb_y_pred = XGBClassifierRunner(dog_x_train, dog_y_train, dog_x_test, dog_y_test)

"""####Cat Data Only"""

cat_df = GetDataSet(data=adoption_training_df, has_all=False, dog_only=False, cat_only=True, categorical=True, cate_func=map_days_to_period)

cat_x_train, cat_x_test, cat_y_train, cat_y_test = train_test_split_helper(cat_df, label_col='days_in_shelter')

cat_x_train, cat_x_test, = standard_scale_data(cat_x_train, cat_x_test,)

"""######**LogisticRegression**


"""

cat_log, cat_log_y_pred = LogisticRegressionRunner(cat_x_train, cat_y_train, cat_x_test, cat_y_test)

"""######**RandomForestClassifier**"""

cat_rfc, cat_rfc_y_pred = RandomForestClassifierRunner(cat_x_train, cat_y_train, cat_x_test, cat_y_test)

"""######**XGBClassifier**"""

cat_rfc_xgb, cat_rfc_xgb_y_pred = XGBClassifierRunner(cat_x_train, cat_y_train, cat_x_test, cat_y_test)